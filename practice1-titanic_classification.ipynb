{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "be1fb74a-ea76-5d12-af9c-21651032ac37",
    "nbpresent": {
     "id": "fc3bcb6d-17bb-42da-9168-60518bcf0a75"
    }
   },
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f35f9107-7b1a-184a-9dbf-51a5b2b3ee67",
    "nbpresent": {
     "id": "76a66fc6-5dab-43d6-b21f-dc0b03579a1e"
    }
   },
   "source": [
    "* Description:\n",
    "    The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "* Problem definition: In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "73c6ae96-3a21-d2ea-3728-9d33adee18ba",
    "nbpresent": {
     "id": "a30a9716-8644-463c-aeb2-fb1956d21c62"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to download the relevant data:\n",
    "\n",
    "Open a user on Kaggle https://www.kaggle.com\n",
    "\n",
    "follow instructions here (https://www.kaggle.com/docs/api?utm_me)\n",
    "\n",
    "Register to competition (https://www.kaggle.com/c/titanic/data) before trying to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (1.5.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from kaggle) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from kaggle) (4.40.2)\n",
      "Requirement already satisfied: python-slugify in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied: six>=1.10 in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from kaggle) (1.13.0)\n",
      "Requirement already satisfied: certifi in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied: python-dateutil in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/yani/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from python-slugify->kaggle) (1.3)\n",
      "titanic.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle\n",
    "! kaggle competitions download -c titanic #Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "907c91be-7361-fe03-6cea-5a9ee12c4ea9",
    "nbpresent": {
     "id": "fb6af155-f074-4699-952e-a361ddc322b6"
    }
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to change the path such that it points to where the data is stored in your computer after downloading it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "5bb5d0e3-39a8-edfd-3776-8b639e2d784d",
    "nbpresent": {
     "id": "8f1113d9-b544-47b8-a294-41e577ea6946"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_sets/titanic/train.csv')\n",
    "test = pd.read_csv('data_sets/titanic/test.csv')\n",
    "y_test = pd.read_csv('data_sets/titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data - the data we will let the model to train on\n",
    "test data - part of the data that we will put asside, and use it very few times (ideally once) to check the performance of the predictive model we built. \n",
    "\n",
    "\n",
    "In this dataset the division to test and train data is predetermined (as it is part of a kaggle competition). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "889004f2-e10d-0687-4ccc-3e4b5a825d57",
    "nbpresent": {
     "id": "6b5eb17b-eba5-4951-8929-16d9ec14c39d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of train data (891, 12)\n",
      "Dimension of test data (418, 11)\n",
      "Dimension of test labels (418, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"Dimension of train data\",train.shape)\n",
    "print (\"Dimension of test data\",test.shape) #This contains only the features (inputs, covariates) of the test data\n",
    "print(\"Dimension of test labels\", y_test.shape) #This is the output (target) of the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to use a subset of features for your prediction. \n",
    "\n",
    "If you are interested in a more detailed description of how to build smart features from this data set, please contact me and I will provide the full data analysis if there is a demand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I am dropping useful features - if you want to do some preprocessing for these features, go ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_drop=  ['PassengerId', 'Name',  'Cabin', 'Ticket']\n",
    "train.drop(labels=label_drop, axis=1, inplace=True)\n",
    "test.drop(labels=label_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data imputation - replace with median and add a column indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass       0\n",
       "Sex          0\n",
       "Age         86\n",
       "SibSp        0\n",
       "Parch        0\n",
       "Fare         1\n",
       "Embarked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not creating Embarked and Fare missing colums as we have very few samples\n",
    "for i in list(train):\n",
    "    if i == 'Age':\n",
    "        if train[i].isnull().any().any():\n",
    "            train[i+'_miss'] = np.where(train[i].isnull(), 1, 0)          \n",
    "        \n",
    "for i in list(test):\n",
    "    if i == 'Age':\n",
    "        if test[i].isnull().any().any():\n",
    "            test[i+'_miss'] = np.where(test[i].isnull(), 1, 0)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the 2 samples of missing embarked with most common value\n",
    "train['Embarked'].fillna((train['Embarked'].mode()[0]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One hot encoding for dichotomous columns\n",
    "train['Sex'] = np.where(train['Sex'] == 'female',1,0)\n",
    "test['Sex'] = np.where(test['Sex'] == 'female',1,0)\n",
    "\n",
    "#For tree based algorithms this is not necessarily needed.\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Embarked'])\n",
    "test = pd.get_dummies(test, columns=['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        0\n",
       "Pclass          0\n",
       "Sex             0\n",
       "Age           177\n",
       "SibSp           0\n",
       "Parch           0\n",
       "Fare            0\n",
       "Age_miss        0\n",
       "Embarked_C      0\n",
       "Embarked_Q      0\n",
       "Embarked_S      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass         0\n",
       "Sex            0\n",
       "Age           86\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           1\n",
       "Age_miss       0\n",
       "Embarked_C     0\n",
       "Embarked_Q     0\n",
       "Embarked_S     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].fillna((train['Age'].median()), inplace=True)\n",
    "test['Age'].fillna((train['Age'].median()), inplace=True)\n",
    "test['Fare'].fillna((train['Fare'].median()), inplace=True) #Have to fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age_miss</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Age_miss  Embarked_C  \\\n",
       "0         0       3    0  22.0      1      0   7.2500         0           0   \n",
       "1         1       1    1  38.0      1      0  71.2833         0           1   \n",
       "2         1       3    1  26.0      0      0   7.9250         0           0   \n",
       "3         1       1    1  35.0      1      0  53.1000         0           0   \n",
       "4         0       3    0  35.0      0      0   8.0500         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the output (target) for the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Survived']\n",
    "Survived_drop=  ['Survived']\n",
    "train.drop(labels=Survived_drop, axis=1, inplace=True)\n",
    "\n",
    "y_test.drop(labels='PassengerId', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code should Go Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict using logistic regression and random forest (think if you want to do some pre-processing (also you are welcome to use features that I dropped in my data cleaning). Try to use the test set not more than 5 times. \n",
    "\n",
    "If you know what is AUC, please use AUC as a measure of performance (and not accuracy, think which is more relevant in this case) \n",
    "\n",
    "If you want to get creative - think of how to impute the data differently than what I have done. \n",
    "\n",
    "The relevant data is found in the following objects:\n",
    "\n",
    "train  - training features\n",
    "test - test features\n",
    "y_train - target for training\n",
    "y_test - traget for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbpresent": {
   "slides": {
    "994dbd29-a1e8-4d6d-b53e-0221075496f3": {
     "id": "994dbd29-a1e8-4d6d-b53e-0221075496f3",
     "prev": null,
     "regions": {
      "72167251-4484-4cd3-9fa9-6afae48011a8": {
       "attrs": {
        "height": 0.8,
        "width": 0.45,
        "x": 0.5,
        "y": 0.1
       },
       "id": "72167251-4484-4cd3-9fa9-6afae48011a8"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
